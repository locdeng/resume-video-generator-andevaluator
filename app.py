# Streamlit UI 
import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM

@st.cache_resource
def load_kogpt():
    tokenizer = AutoTokenizer.from_pretrained("kakaobrain/kogpt")
    model = AutoModelForCausalLM.from_pretrained("kakaobrain/kogpt")
    return tokenizer, model

tokenizer, model = load_kogpt()

# ------------------------------
# app.py
# KoGPT ìê¸°ì†Œê°œì„œ / ì´ë ¥ì„œ Generator
# ------------------------------

import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM

# ------------------------------
# Load model & tokenizer
# ------------------------------
@st.cache_resource
def load_kogpt():
    tokenizer = AutoTokenizer.from_pretrained("kakaobrain/kogpt")
    model = AutoModelForCausalLM.from_pretrained("kakaobrain/kogpt")
    return tokenizer, model

tokenizer, model = load_kogpt()

# ------------------------------
# Streamlit UI
# ------------------------------
st.title("ğŸ‡°ğŸ‡· KoGPT ìê¸°ì†Œê°œì„œ / ì´ë ¥ì„œ ìƒì„±ê¸°")
st.markdown("""
í•œêµ­ì–´ ì…ë ¥ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ìê¸°ì†Œê°œì„œ**ë‚˜ **ì´ë ¥ì„œ**ë¥¼ AIê°€ ìë™ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.  
ì•„ë˜ì— ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³´ì„¸ìš”!
""")

st.sidebar.title("ğŸ› ï¸ ì˜µì…˜")
max_tokens = st.sidebar.slider("ìƒì„± ìµœëŒ€ ê¸¸ì´", 100, 1024, 512, step=50)
temperature = st.sidebar.slider("ì°½ì˜ì„± (Temperature)", 0.5, 1.5, 0.8, step=0.1)

# ------------------------------
# User Inputs
# ------------------------------
doc_type = st.selectbox("ë¬¸ì„œ ì¢…ë¥˜ ì„ íƒ:", ["ìê¸°ì†Œê°œì„œ", "ì´ë ¥ì„œ"])
name = st.text_input("ì´ë¦„:")
age = st.text_input("ë‚˜ì´:")
skills = st.text_area("ë³´ìœ  ê¸°ìˆ /ì—­ëŸ‰:")
experience = st.text_area("ê²½ë ¥ ì‚¬í•­:")
goal = st.text_area("ëª©í‘œ/ì§€ì› ë™ê¸°:")

# ------------------------------
# Prompt Builder
# ------------------------------
def build_prompt(doc_type, name, age, skills, experience, goal):
    prompt = f"""
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {doc_type}ë¥¼ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

- ì´ë¦„: {name}
- ë‚˜ì´: {age}
- ë³´ìœ  ê¸°ìˆ /ì—­ëŸ‰: {skills}
- ê²½ë ¥ ì‚¬í•­: {experience}
- ëª©í‘œ/ì§€ì› ë™ê¸°: {goal}

ì‘ì„±ëœ {doc_type}:
"""
    return prompt.strip()

# ------------------------------
# Generation Button
# ------------------------------
if st.button("âœ… ìƒì„±í•˜ê¸°"):
    if not name or not age:
        st.warning("âš ï¸ ì´ë¦„ê³¼ ë‚˜ì´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”!")
    else:
        with st.spinner("KoGPTê°€ ë¬¸ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
            user_prompt = build_prompt(doc_type, name, age, skills, experience, goal)
            
            inputs = tokenizer.encode(user_prompt, return_tensors="pt")
            
            output = model.generate(
                inputs,
                max_length=max_tokens,
                do_sample=True,
                top_p=0.95,
                temperature=temperature,
                pad_token_id=tokenizer.eos_token_id
            )
            
            result_text = tokenizer.decode(output[0], skip_special_tokens=True)
            # Promptê¹Œì§€ í¬í•¨ëœ ê²°ê³¼ê°€ ë‚˜ì˜¤ë¯€ë¡œ ì˜ë¼ì„œ ê¹”ë”í•˜ê²Œ
            result_only = result_text[len(user_prompt):].strip()
            
            st.success(f"ğŸ‰ {doc_type} ìƒì„± ì™„ë£Œ!")
            st.text_area("âœï¸ ìƒì„±ëœ ë¬¸ì„œ", value=result_only, height=300)

# ------------------------------
# Footer
# ------------------------------
st.markdown("---")
st.caption("ğŸ› ï¸ Made with KakaoBrain KoGPT + Streamlit")
